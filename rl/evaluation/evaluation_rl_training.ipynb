{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward 수렴 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder = '2025_03_21_17_41'\n",
    "\n",
    "# Example usage\n",
    "log_dir_episode = f'/home/songmu/multipath/rl/results/{folder}/logs/episode'\n",
    "log_dir_step = f'/home/songmu/multipath/rl/results/{folder}/logs/step'\n",
    "output_dir = f'/home/songmu/multipath/rl/results/{folder}/logs/output'\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs saved in /home/songmu/multipath/rl/results/2025_03_21_17_41/logs/output\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_combined_episode_logs(log_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Analyze combined episode logs and generate graphs for each metric.\n",
    "\n",
    "    Parameters:\n",
    "        log_dir (str): Path to the directory containing episode logs.\n",
    "        output_dir (str): Path to save the output graphs.\n",
    "    \"\"\"\n",
    "    # List all log files in the directory\n",
    "    log_files = [f for f in os.listdir(log_dir) if f.endswith('.csv')]\n",
    "    if not log_files:\n",
    "        print(\"No log files found in the specified directory.\")\n",
    "        return\n",
    "\n",
    "    # Combine all logs into a single DataFrame\n",
    "    combined_data = pd.DataFrame()\n",
    "    for log_file in log_files:\n",
    "        log_path = os.path.join(log_dir, log_file)\n",
    "        try:\n",
    "            # Read the log file and append to combined DataFrame\n",
    "            log_data = pd.read_csv(log_path)\n",
    "            combined_data = pd.concat([combined_data, log_data], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {log_file}: {e}\")\n",
    "\n",
    "    if combined_data.empty:\n",
    "        print(\"No data found in the logs.\")\n",
    "        return\n",
    "\n",
    "    # Ensure the data is sorted by episode\n",
    "    combined_data.sort_values(by='Episode', inplace=True)\n",
    "\n",
    "    # Plot Total Reward per Episode\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(combined_data['Episode'], combined_data['Return'], marker='o', markersize = 2, label='Return')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Total Reward per Episode')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(output_dir, 'total_reward_per_episode.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Episode Length per Episode\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(combined_data['Episode'], combined_data['Episode Length'], marker='o', markersize = 2, label='Episode Length')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Episode Length')\n",
    "    plt.title('Episode Length per Episode')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(output_dir, 'episode_length_per_episode.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Average Reward per Episode\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(combined_data['Episode'], combined_data['Average Reward (100 eps)'], marker='o', markersize = 2, label='Average Reward')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Average Reward')\n",
    "    plt.title('Average Reward per Episode')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(output_dir, 'average_reward_per_episode.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Average Loss per Episode\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(combined_data['Episode'], combined_data['Average Loss'], marker='o', markersize = 2, label='Average Loss')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.title('Average Loss per Episode')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(output_dir, 'average_loss_per_episode.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Plot Learning rate\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(combined_data['Episode'], combined_data['Learning Rate'], marker='o', markersize = 2, label='Learning Rate')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.title('Learning Rate')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(output_dir, 'learning_rate.png'))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Graphs saved in {output_dir}\")\n",
    "\n",
    "analyze_combined_episode_logs(log_dir_episode, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action distribution plot saved to: /home/songmu/multipath/rl/results/2025_01_26_18_02/logs/output/action_distribution.png\n",
      "SSIM over Steps plot saved to: /home/songmu/multipath/rl/results/2025_01_26_18_02/logs/output/ssim_over_steps.png\n",
      "Data Size over Steps plot saved to: /home/songmu/multipath/rl/results/2025_01_26_18_02/logs/output/data size_over_steps.png\n",
      "Reward over Steps plot saved to: /home/songmu/multipath/rl/results/2025_01_26_18_02/logs/output/reward_over_steps.png\n",
      "Action over Steps plot saved to: /home/songmu/multipath/rl/results/2025_01_26_18_02/logs/output/action_over_steps.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_filtered_logs(log_dir_step, episode_range=None):\n",
    "    \"\"\"\n",
    "    지정된 범위의 에피소드 데이터만 로드하는 함수.\n",
    "    \n",
    "    Args:\n",
    "        log_dir_step (str): Step 로그 파일들이 있는 디렉토리 경로.\n",
    "        episode_range (list or range): 로드할 에피소드 번호 리스트 또는 범위.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: 필터링된 데이터프레임.\n",
    "    \"\"\"\n",
    "    log_files = sorted([os.path.join(log_dir_step, f) for f in os.listdir(log_dir_step) if f.endswith('.csv')])\n",
    "\n",
    "    if not log_files:\n",
    "        print(\"No log files found in the directory!\")\n",
    "        return None\n",
    "\n",
    "    filtered_logs = []\n",
    "    for file in log_files:\n",
    "        # 데이터 로드\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        # 지정된 에피소드 범위만 필터링\n",
    "    if episode_range:\n",
    "            df = df[df['Episode'].isin(episode_range)]\n",
    "\n",
    "    if not df.empty:\n",
    "        filtered_logs.append(df)\n",
    "\n",
    "    if not filtered_logs:\n",
    "        print(\"No logs matched the specified episode range.\")\n",
    "        return None\n",
    "\n",
    "    # 필터링된 데이터를 병합\n",
    "    return pd.concat(filtered_logs, ignore_index=True)\n",
    "\n",
    "def plot_action_over_steps(filtered_logs, output_dir):\n",
    "    \"\"\"\n",
    "    Step별 Action 선택을 시각화하는 함수.\n",
    "    \n",
    "    Args:\n",
    "        filtered_logs (pd.DataFrame): 필터링된 로그 데이터.\n",
    "        output_dir (str): 그래프 저장 디렉토리.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for episode in filtered_logs['Episode'].unique():\n",
    "        episode_data = filtered_logs[filtered_logs['Episode'] == episode]\n",
    "        plt.plot(episode_data['Step'], episode_data['Action'], label=f\"Episode {episode}\", alpha=0.7, linestyle='none', marker='o', markersize=0.7)\n",
    "    \n",
    "    plt.title(\"Action Selection over Steps\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Action\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.7)\n",
    "    \n",
    "    # 그래프 저장\n",
    "    output_path = os.path.join(output_dir, 'action_over_steps.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(f\"Action over Steps plot saved to: {output_path}\")\n",
    "\n",
    "\n",
    "def plot_action_distribution(filtered_logs, output_dir):\n",
    "    \"\"\"\n",
    "    Action 분포를 시각화하는 함수.\n",
    "    \n",
    "    Args:\n",
    "        filtered_logs (pd.DataFrame): 필터링된 로그 데이터.\n",
    "        output_dir (str): 그래프 저장 디렉토리.\n",
    "    \"\"\"\n",
    "    # Action 분포 시각화\n",
    "    action_counts = filtered_logs['Action'].value_counts().sort_index()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    action_counts.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "    plt.title('Action Distribution')\n",
    "    plt.xlabel('Action')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 그래프 저장\n",
    "    output_path = os.path.join(output_dir, 'action_distribution.png')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(f\"Action distribution plot saved to: {output_path}\")\n",
    "\n",
    "def plot_metrics_over_steps(filtered_logs, output_dir):\n",
    "    \"\"\"\n",
    "    Step별 주요 메트릭 시각화 (SSIM, Data Size, Reward).\n",
    "    \n",
    "    Args:\n",
    "        filtered_logs (pd.DataFrame): 필터링된 로그 데이터.\n",
    "        output_dir (str): 그래프 저장 디렉토리.\n",
    "    \"\"\"\n",
    "    metrics = ['SSIM', 'Data Size', 'Reward']\n",
    "    for metric in metrics:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for episode in filtered_logs['Episode'].unique():\n",
    "            episode_data = filtered_logs[filtered_logs['Episode'] == episode]\n",
    "            plt.plot(episode_data['Step'], episode_data[metric], label=f\"Episode {episode}\", linestyle='none', marker='o', markersize=0.7)\n",
    "        \n",
    "        plt.title(f'{metric} over Steps')\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.7)\n",
    "\n",
    "        # 그래프 저장\n",
    "        output_path = os.path.join(output_dir, f'{metric.lower()}_over_steps.png')\n",
    "        plt.savefig(output_path)\n",
    "        plt.close()\n",
    "        print(f\"{metric} over Steps plot saved to: {output_path}\")\n",
    "\n",
    "# Example usage \n",
    "# log_dir_step = '/path/to/logs/step'\n",
    "# output_dir = '/path/to/output'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 원하는 에피소드 범위 설정\n",
    "episode_range = range(160, 161)\n",
    "\n",
    "# 로그 데이터 로드\n",
    "filtered_logs = load_filtered_logs(log_dir_step, episode_range)\n",
    "\n",
    "if filtered_logs is not None:\n",
    "    # Action 분포 시각화\n",
    "    plot_action_distribution(filtered_logs, output_dir)\n",
    "    # Step별 메트릭 시각화\n",
    "    plot_metrics_over_steps(filtered_logs, output_dir)\n",
    "    # Step 별 Action\n",
    "    plot_action_over_steps(filtered_logs, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025_03_18_10_57의 rolling stats가 '/home/songmu/multipath/rl/2025_03_18_10_57_rolling_stats.csv'에 저장되었습니다.\n",
      "2025_03_27_13_46의 rolling stats가 '/home/songmu/multipath/rl/2025_03_27_13_46_rolling_stats.csv'에 저장되었습니다.\n",
      "2025_03_27_13_48의 rolling stats가 '/home/songmu/multipath/rl/2025_03_27_13_48_rolling_stats.csv'에 저장되었습니다.\n",
      "평균 이동 곡선 그래프가 '/home/songmu/multipath/rl' 폴더에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_reward_data(folder, base_path='/home/songmu/multipath/rl/results'):\n",
    "    \"\"\"\n",
    "    지정한 폴더의 에피소드 로그들을 읽어와 결합한 후 정렬된 DataFrame을 반환합니다.\n",
    "    (CSV 파일 내의 'Return' 컬럼이 raw reward 값이라고 가정)\n",
    "    \"\"\"\n",
    "    log_dir = os.path.join(base_path, folder, \"logs\", \"episode\")\n",
    "    log_files = [f for f in os.listdir(log_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    combined_data = pd.DataFrame()\n",
    "    for log_file in log_files:\n",
    "        log_path = os.path.join(log_dir, log_file)\n",
    "        try:\n",
    "            data = pd.read_csv(log_path)\n",
    "            combined_data = pd.concat([combined_data, data], ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(f\"{log_file} 파일 처리 중 오류 발생: {e}\")\n",
    "    \n",
    "    if not combined_data.empty:\n",
    "        combined_data.sort_values(by='Episode', inplace=True)\n",
    "        \n",
    "    return combined_data\n",
    "\n",
    "def calculate_rolling_stats(data, window=10):\n",
    "    \"\"\"\n",
    "    그룹화된 에피소드별 raw reward (Return)를 대상으로\n",
    "    동일한 이동 윈도우(window)를 적용하여 rolling mean을 계산.\n",
    "    \"\"\"\n",
    "    # 동일 에피소드 번호가 있는 여러 raw reward 값들의 산술 평균을 계산합니다.\n",
    "    grouped = data.groupby('Episode')['Return'].agg(['mean']).reset_index()\n",
    "    grouped['rolling_mean'] = grouped['mean'].rolling(window=window, min_periods=1).mean()\n",
    "    return grouped\n",
    "\n",
    "# 분석할 폴더 및 legend에 사용할 라벨 (순서대로 30ms, 40ms, 100ms)\n",
    "folders = ['2025_03_18_10_57', '2025_03_27_13_46', '2025_03_27_13_48']\n",
    "legend_labels = ['30ms', '40ms', '100ms']\n",
    "\n",
    "# 결과 이미지와 CSV 파일 저장을 위한 공통 출력 폴더 설정\n",
    "multi_output_dir = '/home/songmu/multipath/rl'\n",
    "os.makedirs(multi_output_dir, exist_ok=True)\n",
    "base_path = '/home/songmu/multipath/rl/results'\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for folder, label in zip(folders, legend_labels):\n",
    "    data = read_reward_data(folder, base_path=base_path)\n",
    "    if data.empty:\n",
    "        print(f\"{folder} 폴더에 데이터가 없습니다.\")\n",
    "        continue\n",
    "\n",
    "    # 에피소드별 raw reward 데이터에 대해 rolling statistics 계산 (이동 평균만 산출)\n",
    "    stats = calculate_rolling_stats(data, window=10)\n",
    "    \n",
    "    # 계산된 rolling statistics를 CSV 파일로 저장 (나중에 재사용 가능)\n",
    "    csv_path = os.path.join(multi_output_dir, f'{label}.csv')\n",
    "    stats.to_csv(csv_path, index=False)\n",
    "    print(f\"{folder}의 rolling stats가 '{csv_path}'에 저장되었습니다.\")\n",
    "    \n",
    "    # 이동 평균 곡선만 표시합니다.\n",
    "    plt.plot(stats['Episode'], stats['rolling_mean'], label=label, linewidth=2)\n",
    "\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Moving Average Return')\n",
    "# plt.title('Reward Convergence with Moving Average')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(multi_output_dir, 'average_reutrn.png'))\n",
    "plt.close()\n",
    "\n",
    "print(f\"평균 이동 곡선 그래프가 '{multi_output_dir}' 폴더에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multipath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
