# configs/config.yaml

# Setting
mode: train  # 'train' 또는 'eval'
algorithm: 'PPO'  # 'DQN' or 'PPO' 'RDQN'
delay_steps: 2

action_type: scalar # scalar or vector

# training mode
num_episodes: 300
model_save_freq: 10
training_data_split: 0.6  # training 데이터셋 비율
log_save_freq: 1  # 몇 에피소드마다 로그를 저장할지
history_length: 60  # state를 정의할 때 평균 및 분산 계산 시 window size 결정
load_model_path:  # start initial state
# /home/songmu/multipath/rl/results/2025_01_26_18_21/models/ppo_model_episode350.pth

# evaluation mode
num_eval_episodes: 1
model_path: /home/songmu/multipath/rl/results/2025_02_21_20_19/models/ppo_model_episode280.pth

# log path
frame_dir: /home/songmu/multipath/client/logs/2025_02_17_14_14/frames_with_sequence
kt_log_dir: /home/songmu/multipath/server/logs/2025_02_17_13_57/kt_log.csv
lg_log_dir: /home/songmu/multipath/server/logs/2025_02_17_13_57/lg_log.csv

# frame_dir: /home/songmu/multipath/client/logs/2024_12_10_17_00/frames_with_sequence
# kt_log_dir: /home/songmu/multipath/server/logs/2024_12_10_16_45/kt_log.csv
# lg_log_dir: /home/songmu/multipath/server/logs/2024_12_10_16_45/lg_log.csv

# Environment, Reward
# latency_threshold: 40  # ms
latency_threshold: 30  # ms
ssim_threshold: 0.9
gamma_reward: 0.1
state_num: 13

# Normalize 설정
# min_datasize: 500
# max_datasize: 100000
# max_frames_since_loss: 30
# max_frames_since_iframe: 30

min_datasize: 100
max_datasize: 45000
max_frames_since_loss: 10
max_frames_since_iframe: 50

# 에이전트 하이퍼파라미터
learning_rate: 0.001

# PPO
batch_size_ppo: 4096
update_timestep: 4096
mini_batch_size: 512
epsilon_clip: 0.2
k_epochs: 6
entropy_coef: 0.01
value_loss_coef: 0.5
lambda_gae: 0.96  # GAE 람다
gamma: 0.97
network_ppo: 'ActorCritic2'
scheduler_type: LinearLR  # CosineAnnealingLR or LinearLR
scheduler_T_max: 31721             # CosineAnnealingLR에 필요한 매개변수 (T_max)
start_factor: 1.0 # LinearLR
end_factor: 0.1  # LinearLR
total_iters: 150  # LinearLR

actions_vec:
  path:  [KT, LG, Both]
  frame: [I-frame, P-frame]

actions:
  0:
    - KT
    - I-frame
  1:
    - KT
    - P-frame
  2:
    - LG
    - I-frame
  3:
    - LG
    - P-frame
  4:
    - Both
    - I-frame
  5:
    - Both
    - P-frame


# DQN
batch_size_dqn: 128
epsilon_start: 1
epsilon_min: 0.1
epsilon_decay: 0.99
memory_size: 50000
target_model_update_freq: 700
network_dqn: 'AdvancedDQNNetwork'

# RDQN
sequence_length: 50  # 시퀀스 길이
network_rdqn: 'RecurrentDQNNetwork'
burn_in_length: 20